---
title: "THE UNRELENTING HORROR OF the NIH API"
format: html
---

# The NIH Data

This code should get you started with downloading data from the NIH API. I told you it was tricky! This omits the `include_fields` option and downloads all the data for the University of Idaho and Boise State University from Fiscal Year 2013 to Fiscal Year 2024.

You should be able to modify this to get the rest of what you want. When you look at the data frame (`projects_df`), you'll notice that some columns contain multiple entries and their values say something like *2 variables*. This is hierarchical data left over from the transition between json and a tidy dataframe. You are probably going to need one or more of those columns. Try to figure out how to get that information.

```{r}

# Load required libraries
library(httr)
library(jsonlite)
library(dplyr)

# Set the base URL for the API
base_url <- "https://api.reporter.nih.gov/v2/projects/search"


# Build query parameters
query_params <- list(
  criteria = list(
    fiscal_years = 2013:2024, # Specify range of fiscal years
    org_names = list("UNIVERSITY OF IDAHO", "BOISE STATE UNIVERSITY", "IDAHO STATE UNIVERSITY", "WASHINGTON STATE UNIVERSITY", "MONTANA STATE UNIVERSITY", "UNIVERSITY OF MONTANA")),
  offset = 0, # Starting point for fetching results.  Unlikely you'd ever want to change this.
  limit = 500, # Maximum number of results to fetch. Sometimes the API sets a maximum.  NIH does not.
  sort_field = "ProjectStartDate", # Field to sort by.  Largely irrelevant as our visualizations should control this.
  sort_order = "desc" # Sort order
)

# Convert query parameters to JSON format. This part is tricky.  This line converts the list above to a format (json) that the API will recognize.  This is a place where Python is way better than R.
query_json <- toJSON(query_params, auto_unbox = TRUE, null = "null", pretty = TRUE)

# Set header information for the request.  Some instructions to the API about our query.
headers <- c("Content-Type" = "application/json")

# Send a POST request and retrieve response data.  POST is just a type of API interaction.  response is a json object.  Click on it in your environment to see the hierarchical structure.

response <- POST(base_url, body = query_json, encode = "json", httr::add_headers(.headers = headers))

# Check if the request was successful.  Sometimes the error is from our code.  But sometimes it is from the API call.  Status codes help us figure out where any problems might be.
if (status_code(response) == 200) {
  # Extract and parse JSON data
  json_data <- content(response, as = "text", encoding = "UTF-8")
  parsed_data <- fromJSON(json_data, flatten = TRUE)
  
  # Select columns based on the actual JSON data structure. The data frame (technically the tibble) we want is in the results component.  click on parsed_data and you'll see what I mean.
  projects_df <- parsed_data$results
  

  
  # Print the data frame.  This is nice for debugging but you'll eventually want to stop doing this.
  print(projects_df)
} else {
  # Print an error message if data fetching failed
  print(paste("Failed to fetch data: Status code", status_code(response)))
  # Print the full response for debugging purposes
  print(content(response, as = "text"))
}


```

# The NSF Data

```{r}
#getting the NSF data

library(readxl)


# Base URL for the API
base_url <- "https://www.research.gov/awardapi-service/v1/awards.json?awardeeName=%22regents+of+the+university+of+idaho%22"

printFields <- "rpp,offset,id,agency,awardeeCity,awardeeCountryCode,awardeeDistrictCode,awardeeName,awardeeStateCode,awardeeZipCode,cfdaNumber,coPDPI,date,startDate,expDate,estimatedTotalAmt,fundsObligatedAmt,ueiNumber,fundProgramName,parentUeiNumber,pdPIName,perfCity,perfCountryCode,perfDistrictCode,perfLocation,perfStateCode,perfZipCode,poName,primaryProgram,transType,title,awardee,poPhone,poEmail,awardeeAddress,perfAddress,publicationResearch,publicationConference,fundAgencyCode,awardAgencyCode,projectOutComesReport,abstractText,piFirstName,piMiddeInitial,piLastName,piEmail"

# Initialize an empty data frame to store results
NSFtoUI <- tibble()

# Number of results per page (as per API settings)
results_per_page <- 25

# Variable to keep track of the current page number
current_page <- 1

# Variable to control the loop
keep_going <- TRUE

while(keep_going) {
    # Calculate the offset for the current page
    offset <- (current_page - 1) * results_per_page + 1

    # Construct the full URL with offset
    url <- paste0(base_url, "&offset=", offset, "&printFields=", printFields)

    # Make the API call
    response <- GET(url)

    # Check if the call was successful
    if (status_code(response) == 200) {
        # Extract and parse the JSON data
        json_data <- content(response, type = "text", encoding = "UTF-8")
        parsed_data <- fromJSON(json_data, flatten = TRUE)

        # Extract the 'award' data and add to the all_awards data frame
        awards_data <- parsed_data$response$award
        NSFtoUI <- bind_rows(NSFtoUI, as_tibble(awards_data))

        # Debug: Print the current page number and number of awards fetched
        print(paste("Page:", current_page, "- Awards fetched:", length(awards_data$id)))

        # Check if the current page has less than results_per_page awards, then it's the last page
        if (length(awards_data$id) < results_per_page) {
            keep_going <- FALSE
        } else {
            current_page <- current_page + 1
        }
    } else {
        print(paste("Failed to fetch data: Status code", status_code(response)))
        keep_going <- FALSE
    }
}
```
